[/
  Copyright 2013 Christopher Kormanyos.
  Copyright 2015 John Maddock.
  Copyright 2015 Paul A. Bristow.
  Copyright 2015 Nikhar Agrawal.

  Distributed under the Boost Software License, Version 1.0.
  (See accompanying file LICENSE_1_0.txt
  or copy at http://www.boost.org/LICENSE_1_0.txt).
]

[article Boost.Fixed-point
    [quickbook 1.7]
    [copyright 2013, 2015 Christopher Kormanyos]
    [license
         Distributed under the Boost Software License, Version 1.0.
         (See accompanying file LICENSE_1_0.txt or copy at
         [@http://www.boost.org/LICENSE_1_0.txt])
    ]
    [id fixed]
    [authors [Kormanyos, Christopher], [Maddock, John], [Agrawal, Nikhar], [Bristow, Paul A.]]
    [/last-revision $Date: 2011-07-08 18:51:46 +0100 (Fri, 08 Jul 2011) $]
] [/article Boost.Fixed-point]

[warning This is NOT yet a Boost library and is subject to change and development.]

[caution This documentation is in a very rudementary state and contains many errers and ommisions!]

[import ../../../tools/auto_index/include/auto_index_helpers.qbk]
[/ auto_index_helpers.qbk MUST be FIRST included file!]
[/If index enabled on the command line fixed_point\doc>b2 --enable-index --hash]
[/If enable index, then  --hash option is essential because names become to long.]
[/The message is entirely inscrutable!]

[import html4_symbols.qbk]

[/import ../example/fixed_point_snips.cpp -see example and other sections]

[template super[x]'''<superscript>'''[x]'''</superscript>''']
[template sub[x]'''<subscript>'''[x]'''</subscript>''']

[template equation[name]  '''<inlinemediaobject>
<imageobject role="html">
<imagedata fileref="../'''[name]'''.png"></imagedata>
</imageobject>
<imageobject role="print">
<imagedata fileref="../'''[name]'''.svg"></imagedata>
</imageobject>
</inlinemediaobject>''']

[/ External links]
[def __cpp_standard [@http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4382.pdf C++ draft standard]]
[def __boost [@http://www.boost.org/ Boost]]
[def __boost_archives [@http://lists.boost.org/Archives/boost/ Boost archives]]
[def __boostroot [@boost: Boost root ./modular-boost]]
[def __boost_license [@http://www.boost.org/LICENSE_1_0.txt Boost License]]
[def __multiprecision [@boost:/libs/multiprecision/doc/html/index.html Boost.Multiprecision]]
[def __serialization [@http://www.boost.org/doc/libs/1_58_0/libs/serialization/doc/index.html Boost.Serialization]]
[def __cpp_int [@http://www.boost.org/doc/libs/release/libs/multiprecision/doc/html/boost_multiprecision/tut/ints/cpp_int.html cpp_int]]
[def __cpp_dec_float [@boost:/libs/multiprecision/doc/html/boost_multiprecision/tut/floats/cpp_dec_float.html cpp_dec_float]]
[def __cpp_bin_float [@boost:/libs/multiprecision/doc/html/boost_multiprecision/tut/floats/cpp_bin_float.html cpp_bin_float]]
[def __boost_test [@boost:/libs/test/doc/html/index.html Boost.Test]]
[def __boost_timer [@boost:/libs/timer/doc/index.html Boost.Timer]]
[def __boost_test_fp [@boost:/libs/test/doc/html/boost_test/users_guide/testing_tools/testing_floating_points.html Boost.Test floating-point comparison]]
[def __boost_math_fp [link math_toolkit.float_comparison Boost.Math floating-point utilities]]
[def __boost_math_constants [@http://www.boost.org/doc/libs/release/libs/math/doc/html/math_toolkit/constants.html Boost.Math constants]]
[def __multiprecision_limits_table [@http://www.boost.org/doc/libs/release/libs/multiprecision/doc/html/boost_multiprecision/tut/limits/limits32.html Numeric limits for a 32-bit platform]]
[def __float_distance [@boost:/libs/math/doc/html/math_toolkit/next_float/float_distance.html Boost.Math float_distance]]
[def __ulp [@http://en.wikipedia.org/wiki/Unit_in_the_last_place  Unit in the last place (ULP)]]
[def __SSE2 [@http://en.wikipedia.org/wiki/SSE2 SSE2 instructions]]
[def __WolframAlpha [@http://www.wolframalpha.com/ Wolfram Alpha]]
[def __ARM_architecture  [@https://en.wikipedia.org/wiki/ARM_architecture ARM architecture]]
[def __Q_format [@https://en.wikipedia.org/wiki/Q_(number_format) Q number format]]
[def __floating_point  [@http://en.wikipedia.org/wiki/Floating_point Floating point]]
[def __epsilon [@http://en.wikipedia.org/wiki/Machine_epsilon machine epsilon]]
[def __ADL [@http://en.cppreference.com/w/cpp/language/adl Argument Dependent Lookup (ADL)]]
[def __function_template_instantiation [@http://en.cppreference.com/w/cpp/language/function_template Function template instantiation]]
[def __fundamental_types [@http://en.cppreference.com/w/cpp/language/types fundamental types]]
[def __guard_digits [@http://en.wikipedia.org/wiki/Guard_digit guard digits]]
[def __representable [@http://en.wikipedia.org/wiki/Floating_point#Representable_numbers.2C_conversion_and_rounding representable]]
[def __IEEE754 [@https://en.wikipedia.org/wiki/IEEE_floating_point IEEE floating-point]]
[def __float_format [@https://en.wikipedia.org/wiki/Single-precision_floating-point_format 32-bit float format]]
[def __double_format [@https://en.wikipedia.org/wiki/Double-precision_floating-point_format 64-bit double format]]
[def __quad_format [@https://en.wikipedia.org/wiki/Quadruple-precision_floating-point_format 128-bit quad format]]
[def __n3352 [@http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2012/n3352.html C++ Binary Fixed-Point Arithmetic N3352]]
[def __CMK_realtime [@10.1007/978-3-642-34688-0 Real-Time C++, C M Kormanyos]]
[def __NaN [@https://en.wikipedia.org/wiki/NaN NaN]]
[def __nan [@http://www.cplusplus.com/reference/cmath/nan-function/ C++ nan function]]
[def __infinity [@http://www.cplusplus.com/reference/cmath/INFINITY/?kw=INFINITY  infinity]]
[def __isnan [@http://www.cplusplus.com/reference/cmath/isnan/?kw=isnan  isnan function]]
[def __isinf [@http://www.cplusplus.com/reference/cmath/isinf/  isinf function]]
[def __numeric_limits [@http://www.cplusplus.com/reference/limits/numeric_limits/ numeric_limits]]
[def __edge [@https://en.wikipedia.org/wiki/Edge_case edge case]]
[def __corner [@https://en.wikipedia.org/wiki/Corner_case corner case]]
[def __boundary [@https://en.wikipedia.org/wiki/Boundary_case boundary case]]
[def __significand [@https://en.wikipedia.org/wiki/Significand significand]]
[def __C_math [@http://en.cppreference.com/w/cpp/numeric/math C math]]
[def __is_fundamental [@http://en.cppreference.com/w/cpp/types/is_fundamental std::is_fundamental]]
[def __is_arithmetic [@http://en.cppreference.com/w/cpp/types/is_arithmetic std::is_arithmetic]]
[def __is_floating_point[@http://en.cppreference.com/w/cpp/types/is_floating_point std::is_floating_point]]
[def __is_iec559 [@http://en.cppreference.com/w/cpp/types/numeric_limits/is_iec559 std::numeric_limits::is_iec559]]
[def __cardinal [@https://en.wikipedia.org/wiki/Cardinal_number  cardinal]]
[def __radix [@https://en.wikipedia.org/wiki/Radix  radix]]

[/Links to classes etc]

[def __negatable [classref boost::fixed_point::negatable  negatable]]

[/Unclear how to get a link to the tempate parameters??? So link to class negatable for now.]
[def __range [classref boost::fixed_point::negatable  integral_range]]
[def __resolution [classref boost::fixed_point::negatable  fractional_resolution]]

[/def __range [classref boost::fixed_point::negatable::integral_range  integral_range]]
[/def __resolution [memberref boost::fixed_point::negatable::fractional_resolution  fractional_resolution]]
[/def __round [memberref boost::fixed_point::negatable  round_mode]]
[/def __overflow [memberref boost::fixed_point::negatable  overflow_mode]]

[def __round_fastest [classref boost::fixed_point::round::fastest  round::fastest]]
[def __round_negative [classref boost::fixed_point::round::mode  round::negative]]
[def __round_truncated [classref boost::fixed_point::round::fastest  round::truncated]]
[def __round_positive [classref boost::fixed_point::round::fastest  round::positive]]
[def __round_classic [classref boost::fixed_point::round::fastest  round::classic]]
[def __round_nearest_even [classref boost::fixed_point::round::fastest  round::nearest_even]]
[def __round_nearest_odd [classref boost::fixed_point::round::fastest  round::nearest_odd]]

[/ overflow template parameter options]
[def __overflow_undefined [classref boost::fixed_point::overflow::undefined overflow::undefined]]
[def __overflow_impossible [classref boost::fixed_point::overflow::undefined overflow::impossible]]
[def __overflow_modulus [classref boost::fixed_point::overflow::undefined overflow::modulus]]
[def __overflow_saturate [classref boost::fixed_point::overflow::undefined overflow::saturate]]
[def __overflow_exception [classref boost::fixed_point::overflow::undefined overflow::exception ]]
[def __pi [memberref boost::fixed_point::negatable::constant_maker::pi pi()]]
[def __ln_two [memberref boost::fixed_point::negatable::constant_maker::ln_two]]

[/Links to sections within fixed_point]
[def __examples [link fixed.examples examples]]
[def __intro [link fixed.intro introduction]]

see __examples.

see __intro

[section:intro Introduction]
The Fixed-point Library provides fixed-point types in C++ that have different
range and precision than C++'s ordinary built-in types.
The  Fixed-point types can also interoperate with the
built-in types in C++ using clearly defined conversion rules.
This allows Boost.Fixed-point to be used for all
kinds of mathematical calculations involving integer,
rational and floating-point types requiring extended range and precision.

The value of a binary fixed-point type is an integral value that has a fixed number of binary digits before the binary point,
and another fixed number of fractional binary digits after the point.

The __Q_format is often used to specify the number of bits used.

For example, a G15.16 representation has  a sign bit,
15 bits before the binary point and 16 bits for the fractional part after the point.
This format fits neatly into a 32-bit two's complement signed integer.

A tiny G7.8 representation has a sign bit, 7 bits of integer part before the binary point,
and 8 bits for the fractional part.

The Q7.8 represent can hold integer part values from 0 to 2[super 2] = 127,
and fraction part from 0 to 1/2[super 8] = 1/256 = 0.00390625

Giving a total spread of values from about 0.004 to 127.996.

[[<7,-8>] [7] [-8] [15] [16] [1.17e-002] [-1.3e+002] [0.0039] [1.3e+002]] ????????????????? eps correct?

The integer part is located as more significant than the fractional part.
This means that if there is a carry from an addition to the fractional part,
it simply carrys into the integer part, which means that fast integer instructions can be used.

So fixed-point trades range and precision for (potentially) improved efficiency using integer computation.

[section:why_fixed_point Why Fixed-Point?]

For most computing tasks, floating-point works fine.

* The layout is very cleverly devised to provide a good resolution and a wide exponent range
making very efficient use of the 32 and 64 bits available
(including an cunning extra implicit significand bit).

* Hardware microcode, refined for decades, provides very fast instructions.

So why would one prefer fixed-point?

* The hardware CPU does not have instructions or emulation for floating-point.
Typical examples are 8 and 16-bit microcontrollers used in industrial and consumer devices,
especially vehicles.

* The RISC CPU provides software emulation of floating-point (for example, __ARM_architecture ) but it is not fast enough.

* Storing many floating-point values takes up more memory than would be possible using `fixed_point`.
Memory is cheap, but using less can speed I/O and reduce cache misses.

* If a resolution greater than `double` is required, `fixed_point` may prove faster.[br]
Software like __multiprecision can provide much higher resolution and higher exponent ranges,
but at a great cost in compute time, often a hundred-fold slower.[br]
Fixed-point using many bits, for example 256-bit, can provide very high resolution,
while executing faster than an equivalent __multiprecision type (provided
the reduced exponent range can be tolerated).

[endsect] [/section:why_fixed_point Why Fixed-Point?]



[endsect] [/section:intro Introduction]

[section:examples Examples]

[section:numeric_limits Example of a fixed_point type and its numeric_limits]

[import ../example/fixed_point_demo_basic.cpp]

In order to use the fixed_point library, we first need an include:

[fixed_point_include_1]

Then it is convenient (because we are likely to reuse the type name often)
to define a `typedef` for our chosen fixed-point type

[fixed_point_typedef_1]

This example uses the fixed-point class __negatable
(the analog of a signed floating-point) defined to have
a template parameter __resolution of 15
and a template parameter __range of -16.

(For simplicity, we use the defaults for the other template parameters,
`round_mode` = __round_fastest and `overflow_mode` = __overflow_undefined).

This means that 15 bits are used for the __significand of fraction part and
16 for the binary exponent.

We can show the __numeric_limits for this type thus:

[show_numeric_limits_1]

and the output is:

[numeric_limits_output_1]

Next we can use this defined fixed-point type, constructing from two integer values to avoid
any conversion from a floating-point value whose value is probably not be exactly __representable.
This ensures no loss of precision or double rounding during construction.

[fixed_example_1]

We can inspect the __significand or fraction (also called  mantissa but this term is now deprecated)
and the exponent parts using the using __C_math function `frexp`, and alter the exponent using `ldexp`.

Of course, other __C_math functions (`#include <cmath>`) are available.

The user can simply call `sqrt(negatable)` without requiring any namespace decoration.

TODO Examples snippet needed here.

(See rationale for more details on this).

[warning Some __C_math functions are not applicable to `fixed_point` values;
others may not yet be implemented.]

[endsect] [/section:numeric_limits Example of a fixed_point type and its numeric_limits]

[endsect] [/section:examples Examples]

[section:conversions Constructing and Interconverting Between Number Types]
All of the number types that are based on `number` have certain conversion rules in common.
In particular:
[endsect] [/section:conversions Constructing and Interconverting Between Number Types]

[section:mixed Mixed Precision Arithmetic]
Mixed precision arithmetic is fully supported by the library.  ?????

There are two different forms:

* Where the operands are of different precision.
* Where the operands are of the same precision, but yield a higher precision result.

Some design choices were made.

For example, the result of `(a + b)` has the type of ['a].
Some might argue that the result of (a + b) should
have the highest precision.
It's easy to implement either way; it's just a design choice.

For mixed-math comparison, the supra-negatable type
is created from the maximum of both range and resolution.
A comparison is then made.

This results in such comparisons like

  negatable<4, -8>(1) / 3 != negatable<3, -11>(1) / 3

And the result is symmetric, otherwise, we might be surprized that
  `(a == b)`
and
  `(b != a)`

It's another design choice.

[endsect] [/section:mixed Mixed Precision Arithmetic]

[section:constants Constants]
[import ../example/fixed_point_constants.cpp]

Constants (as far as they are yet implemented) are easily used.

The underlying values are from __boost_math_constants and are used to construct fixed_point types
with a suitable precision for the number of bits in the significand.

To start, we can generate a 'reference' value using __multiprecision, say with 50 decimal digits precision.

[bin_float_50_pi]

Note how we ensure that only significand digits ['for the type] are shown by using

  std::setprecision(std::numeric_limits<cpp_bin_float_50>::digits10)

Then we can generate using a typical fixed_point type that will use a 64-bit integer as its underlying representation.

[fixed_point__constant]

Then a tiny (and so rather imprecise) fixed_point type that will fit into a single byte.

The result would almost meet the requirements of the
[@https://en.wikipedia.org/wiki/Indiana_Pi_Bill Indiana pi bill]!

Finally a much more precise fixed_point type that will fit into 128-bit 16-byte.

[fixed_point_precise_constant]

The full code is at [@../../example/fixed_point_constants.cpp  fixed_point_constants.cpp].

[endsect] [/section:constants Constants]

[section:how_to_tell How to Determine the Kind of a Number From `std::numeric_limits`]

Based on the information above, one can see that different kinds of numbers can be
differentiated based on the information stored in `std::numeric_limits`.  This is
in addition to the `traits class`
[@http://www.boost.org/doc/libs/release/libs/multiprecision/doc/html/boost_multiprecision/ref/number.html#boost_multiprecision.ref.number.traits_class_support traits class support]
provided by this library.

[endsect] [/section:how_to_tell How to Determine the Kind of a Number From `std::numeric_limits`]

[section:fixed_versus_float Comparison of Fixed-point and Floating-point Formats]

We can compare the ubiquitous __IEEE754 types

* __float_format  1 sign bit, 8 exponent bits, 23 stored bits  (+1 implicit not-stored bit)

* __double_format 1 sign bit, 11 exponent bits, and 52 stored bits (+1 implicit not-stored bit)

and the extended precision type (usually implemented in software, and thus much slower)

* __quad_format 1 sign bit, 15 exponent bits, 112 stored bits (+1 implicit not-stored bit)

Using fixed point `negatable`, we can chose make quite different splits between exponent (range) and significand (resolution).

For example, to match the range of `float` using only 32-bit, we can define

  typedef boost::fixed_point::negatable<11, -20> fixed_point_type;

or we can use all 31 bits for resolution (still need one sign bit for signed type `negatable`)

  typedef boost::fixed_point::negatable<0, -30> fixed_point_type;

or we can use nearly all bits for range with

  typedef boost::fixed_point::negatable<29, -2> fixed_point_type;

Note that not all the `std::numeric_limits` member constants and functions
are meaningful for all user-defined types (UDT),
such as the decimal and binary multiprecision types provided here.
More information on this is given in the sections below.
[#numeric_limits_tables] [/ Anchor for Tables of values for numeric_limits for various built-in and cpp_bin_float types]

[include fixed_point_types_table.qbk] [/Complete section containing generated table]
[include floating_point_types_table.qbk] [/Complete section containing generated table]

See [link fixed.fixed_versus_float.fixed_point_limits fixed_point numeric_limits_tables],
and [link fixed.fixed_versus_float.floating_point_limits floating_point numeric_limits_tables.]

(A wider range of floating-point types, including __multiprecision, is at __multiprecision_limits_table).

[h3:type_example Examples of boost::fixed_point::negatable<11, -20>]

This type has a similar distribution of bits usage to `float`
except that IEEE floating point types have an implicit bit that is not stored.

Epsilon is 9.54e-7 compared to `float` 1.2e-7
The range is 2000 compared to `float` 3.4e38.


If we use nearly all the bits for range, (`negatable<29,-2>`) then `epsilon` is 0.25,
but `max `is 5.4e8.

If we try to use all bits for range, then this is not support and a `static assert` warns thus

  Error: The fractional resolution of negatable must be negative and include at least 1 fractional bit.

This would be the same as using a 32-bit `int` whose `max` is = 2147483647 or 2.14e9,
and conceptually `epsilon` would be unity.
(For integral types `std::numeric_limits<>::epsilon()` is not meaningful and is left as zero).
Using all possible bits for range `negatable<30,-1>` has a `max` of half of `int` and an `epsilon` of 0.5.
These two extreme example probably do not have much practical use.

If we use all 31 bits for resolution, then `max` is merely unity, so we can only store fractions <= 1,
but `epsilon` is reduced to 9.3e-10, much less than `float`, so this might be useful.






[endsect] [/section:fixed_versus_float Comparison of Fixed-point and Floating-point Formats]

[section:headers Header File Structure]

[table Top level headers
[[Header][Contains]]
[[boost/fixed_point/fixed_point.hpp] [negatable type]]
]

[table Implementation Headers
[[Header][Contains]]
[[boost/fixed_point//detail/fixed_point.hpp] [negatable impemention details]]
]

[endsect] [/section:headers Header File Structure]

[section:design Design, Implementation and Rationale]

[section:history Historial discussions]

In response to Lawrance Crowl proposal __n3352, there are a thread on the

__boost discussion list. See this thread on
[@http://lists.boost.org/Archives/boost/2012/04/191987.php]
on the __boost_archives.

Vicente Botet Escriba produced a prototype at
[@http://svn.boost.org/svn/boost/sandbox/fixed_point]
asked a number if questions,
and replies from the current author Christopher Kormanyos
(that provided the basis for the implementation here) were:

First up, one might want to consider some top-level requirements.
* How might fixed-point fit with an extended complex class?
- If Boost.Multiprecision or a multiprecision type is ever
specified, how might fixed-point fit with it.
- If a multiprecision integer type ever gets specified, should
the representation of fixed-point be allowed to use it for
mantissa and decimal parts?

* Should integers and reals be represented by separated classes?
I don't see the need for integers in the first place.
I'm wondering if the library will be simpler as the operations are not
the same. If we have only one class, enable_if should be used to make
the difference.

* Should signed and unsigned be represented by separated classes?
Yes, in my opinion.
I guess, perhaps, the separate sign information might be a necessity.
But I'm not sure.
I think that when a single word is enough to represent the fixed-point
2's complement is the bets choice. When more than a word is needed,
having the sing on all the word is a lost of space, and as you say
whether it is represented represented by left-most word/limb or as a
separated data should be an internal decision. In this case using more
space seems IMO to be a minor issue.

* Should the library use a specific representation for signed numbers (separated sign, 2-complement? Let the user choose?
Very good question. A separate bool flag for sign slows down the library and increases
storage requirements. The sign of the left-most limb could be the sign. But this
breaks down for all-fractional types. I guess, perhaps, the separate sign information
might be a necessity. But I'm not sure.

* Should the library provide arbitrary range and resolution and allocators?
Unfortunately, the allocator seems necessary for high digit counts.
But perhaps a hybrid container with compile-time width for low limb-count
and allocation for a (specifiable, zero allowed) higher limb count could be used here.
But be sure to make fixed-point fast for low digit counts, possibly
using template specialization when the fixed-point can be represented
by a built-in integer type (in assiciation with "get my int type" compile-time helper templates).
This is what I have done in the past. Low digit counts is the key range for fixed.

* Should the library be open to overflow and rounding or just implement some of the possible policies? and in this case which ones?
Where do you start, where do you stop?
This is like the sign bit. Do you want extra information
for the sub-normals or use some magic values?

* Should fixed_point be convertible to/from integer/float/double?
Yes, absolutely, in my opinion. Implicit or explicit conversion?

* Could the result of an arithmetic operation have more range and resolution than his arguments?
No. But copy construction and copy assign maybe, whereby the LHS
dictates the digit count.

* Is there a need for a specific fixed_point I/O?
* Is there a need for a specific I/O?
Yes.

* is there a need for radix other than 2 (binary)?
Coming from a guy who has written [*a lot] of specialized number classes...
I have always been haunted by radix-10. Never again for me.
Radix-2 and don't look back (my opinion).
I prefer also to concentrate on Radix-2 and leave Radix-10 for another library.

* Should the library implement the basic functions, or should it imperatively implement the C++11 math functions? Could a first version just forward to the c++11 math functions?
It should fit in with Boost.Multiprecision, if there ever is such a thing.
Users like me who need a tiny set of trig functions for, say, an
8-bit controller can roll-their-own via template specialization.
Don't even get started with Cordic, Chebyshev, polynomial expansion,
Don't even get started with cordic, Chebyshev, polynomial expansion,
Pade, Taylor, Newton-Raphson, FFT multiplication, AGM, etc., etc., etc. and the rest.
Just make the numbers! We will be happy for that because it's really a lot.
C++ should have the templated math functions and an extended complex type
elsewhere. You just need to make the number types.

* Should the library support just one of the know ways to name a fixed-point, a U(a,b), nQm, ...? Provide some ways to move from one to another?

* Could expect the same/better performances respect to hand written code?
It's implementation-dependent. But if your 7.8 and 15.16 signed splits are
slower than single-precision float on an 8-bit core, you will get flack for it.

* What should be the size used by a fixed_point instance? _fast? _least? Should the user be able to decide which approach is better for his needs?
It's implementation defined. For small digit counts, I would try to fit it in
a built-in type. For medium digit counts, a fixed, optionally fixed-hybrid container
of std::uint_fast32_t. For very high counts, use an established fast integer
representation with its own fast-multiply (like a potential Boost.Multiprecision).

* Which should be the namespace? boost? boost/fixed_point? boost/binary_fixed_point? boost/bfp?
For me, boost/fixed_point.

Phil Endecott observed on overflow:

"Some people conflate fixed point with features like saturation, which
I would prefer to decouple. Fixed-point arithmetic without saturation
is useful, as is integer arithmetic with saturation. So I'd prefer to
make them orthogonal, but compatible, concepts. "

[endsect] [/section:history Historial discussions]

[section:layout Layout]

There is a (most significant) bit used for sign, zero if positive, one if negative.

There is [*no] implicit bit as found in most floating-point formats.

[endsect] [/section:layout Layout]

[section:limits Numeric Limits]

[@http://www.exploringbinary.com/ Exploring Binary]

[import  ../example/fixed_point_limits.cpp]

[endsect] [/section:limits Numeric Limits]

[section:macros  Preprocessor Options to disable some features]

Some macros are becoming available to disable some features
that may improve the usefulness of fixed_point in certain applications.

* BOOST_FIXED_POINT_DISABLE_MULTIPRECISION,
defined to disable the use of Boost.Multiprecision
for back-ends of the fixed-point classes.
(not yet implemented).

* BOOST_FIXED_POINT_DISABLE_WIDE_INTEGER_MATH,
defined to avoid using the unsigned_large_type. This option
is intended for systems with limited integer widths
such as bare-metal microcontrollers.[br]
When used in combination with BOOST_FIXED_POINT_DISABLE_MULTIPRECISION,
the this option is intended to provide fixed-point representations
with up to 64-bits (if 64-bit integral types are available)
without requiring any of Boost.Multiprecision.
(not yet implemented).

* BOOST_FIXED_POINT_DISABLE_IOSTREAM defined to disable
all I/O streaming and the inclusion of associated standard
library headers.[br]
This is intended to eliminate I/O stream
overhead, in particular for bare-metal microcontroller projects.
(implemented but not tested).

[/TODO needs a compile-fail test for this macro?]

For an example, see	[@../../example/fixed_point_no_io.cpp fixed_point_no_io.cpp].

* BOOST_FIXED_POINT_DISABLE_CPP11 would decide
to support an optional back-port to C++03 and eliminate
the use of all C++11 language elements. This might send the
wrong message about language technology, but could potentially
increase the range of potential target compilers (especially
for embedded systems). (not yet implemented).

[endsect] [/section:macros  Preprocessor Options to disable some features]

[section:rounding Rounding]

Round has emerged as the most contentious and difficult area.

[#combinatorial_explosion]
Our starting point has been __n3352 that specifies seven rounding modes.
All have some uses and some logic for their inclusion.

Five overflow modes are also specified and this leads to combinatorial explosion,
for example potentially requiring 35 specializations of __limits for each fixed_point type.
So far, only the __negatable class has been implemented, but __n3352 also
describes  nonegative unsigned versions
(as well as integer-only arithmetic __cardinal and signed integral),
potentially at least doubling the code required.

Other libraries are tackling the problem of overflow (and underflow) with integral types in so-called
'safe' integers.


For the rounding mode nearest_even, if the 1/2 __ULP bit 1,
then the result of any operation that leads to a result in the range ['\[x, x+ 1/2 ULP\]]
would round to x and in the range ['(x+1/2ULP, x+1)] would round to x+1.

If the 1/2 __ULP bit is 0, however, then any operation that leads to an intermediate value in the range ['\[x, x+1)] would round to x.

[endsect] [/section:rounding Rounding]

[section:overflow Over and Underflow]

[section:mixed_mode Mixed-mode]

Mixed math  are operations using fixed-point types of [*different range and/or precision].

The minimal set of  needs:

* mixed-math ctors.
* mixed math copy ctor.
* mixed-math global operators add, sub, mul, and div.
* mixed-math comparison operators.

Desing choices were made that the result of ['(a + b)] has the type of ['a].

This might be controversial,
as some might argue that the result of ['(a + b)] should
have the highest precision. It's easy to implement either
way, just a design choice.

For mixed-math comparison, the supra-negatable type
is created from the [*maximum of both range and resolution].
A comparison is then made.

This results in such things like

  negatable<4, -8>(1) / 3 != negatable<3, -11>(1) / 3

And the result is symmetric. Otherwise, we might
end up with (a == b) and (b != a). It's another
design choice.

[endsect] [/section:mixed_mode Mixed-mode]


[endsect] [/section:overflow Over and Underflow]

[section:infinity Infinity and NotANumber (NaN)]

Unlike floating-point types, the fixed-point types (may)
occupy the entire underlying integer type,
and no bit patterns are reserved for __NaN or __infinity.
The `bool std::numeric_limits<T>::has_infinity`
and `bool std::numeric_limits<T>::has_quiet_NaN` both
return `false` for all fixed-point types.

Lack of an encoding for infinity or NaN means that
overflow or underflow must be signalled differently.
A template parameter is provided to control this.

[endsect] [/section:infinity Infinity and NotANumber (NaN)]

[section:cmath C math functions injected into global namespace]

All implemented __C_math functions are injected into the global namespace
using statements like

  using boost::fixed_point::sqrt;

This is very convenient as it allows the user to simply call `sqrt(negatable)` without
requiring any namespace decoration. In this way, the `<cmath>`
functions of the negatable class work just like those for
built-in types in the C-language header `<math.h>`.

So the user can just write:

  fixed_point_type x(42);
  sqrt(x);

(The same strategy  is used in __multiprecision so that types like __cpp_bin_float can use math functions freely).

[endsect] [/section:cmath C math functions injected into global namespace]


[section:testing Testing]

Our testing is necessarily focussed on typical use cases and __boundary __edge and __corner cases.

We have performed round-trip testing.

This involves constructing a fixed_point type from decimal digits strings like '0.001, 0.002 ...'
This fixed-point representation is output to a stringstream and then read back into another
fixed-point variable, and the two checked for equality,

This test can be performed for all possible values of small bit-count fixed-point types,
but this would take unfeasible test times for more than about 32-bit,
so roughly random values covering the entire range of possible binary patterns
are used for test values instead.

[note History Random testing was used to track bugs in Microsoft Visual Studio stream
input from decimal digit strings.
A fault was originally discovered by a user of __serialization when he found (after much debugging)
a single value of  de-serialized data that was 1-bit different from that originally written.
Random value testing then revealed that a small range of values could not be round-tripped in this way,
and a third of the values in this range were 1-bit different.
The __cpp_standard does not (yet) ['require] input from decimal digit strings to the nearest __representable value,
but while other [@http://www.exploringbinary.com/visual-c-plus-plus-strtod-still-broken/#more-565 examples]
were also found in all compilers, most are now achieve correct conversion for all values.
]

[endsect] [/section:testing Testing]

[endsect] [/section:design Design, Implementation and Rationale]

[section:faq Frequently Asked Questions FAQ]

#['When should I consider using a fixed-point type?] [br]
Fixed-point allows you to provide a lower or higher range and/or a lower or higher precision.
#['Will a fixed-point type use less memory?] [br]
If you base the fixed-point type a small underlying integer type, then it will be more efficient.
#['Will a fixed-point type run faster than floating-point type?]  [br]
If there is no hardware floating-point, then is very likely to run much faster.
If you require a very high range or precision that would require __multiprecision or similar
high or arbitrary precision type, then for the same precision or range, it will probably be quicker,
possibly much quicker.
#['How can I avoid using iostream on a bare-metal microcontroller without any peripherals?] [br]
`#define BOOST_FIXED_POINT_DISABLE_IOSTREAM`.

[endsect] [/section:main_faq Frequently Asked Questions FAQ]

[section:perf Performance Comparison]

TODO

[endsect] [/section:perf Performance Comparison]

[section:map Roadmap]

[h4 1.?]

* First Release.
[h4 Post review changes]

[h4 Pre-review history]

[h4 Pre-Review Comments]

* 2015 Christopher Kormanyos  refines the code with the aid of GSoC student Nikhar Agrawal.

* 2013, Christopher Kormanyos develops the all C++ arithmetic fixed point code.

[endsect] [/section:map Roadmap]

[section:todo TODO]

Implementation of all rounding modes and overflows. TODO

[endsect] [/section:todo TODO]

[section:ack Acknowledgements, Thanks and Credits]

This library would not have happened without:

* Christopher Kormanyos' C++ decimal number code.

* [@http://www-cs-faculty.stanford.edu/~uno/taocp.html "The Art Of Computer Programming"],
Donald E. Knuth, Volume 2: Seminumerical Algorithms, Third Edition
(Reading, Massachusetts: Addison-Wesley, 1997), xiv+762pp. ISBN 0-201-89684-2

We are grateful for Google for support of Nikhar Agrawal for support through the
[@http://code.google.com/soc/2007/ Google Summer of Code (2015) program].

[@http://lists.boost.org/Archives/boost/2012/04/191987.php Vicente Botet Escriba ] posed a lots of questions about a design.
As a result of reading Lawrence Crowl's proposal __N3352,
Vicente Botet Escriba prototyped a [@http://svn.boost.org/svn/boost/sandbox/fixed_point fixed-point library] in 2013.

[@http://2015.cppnow.org/participant/vicente-j-botet-escriba/ Phil Endecott reviewed past discussions on fixed-point.]


[endsect] [/section:ack Acknowledgements]

[section:references References]

#__n3352

# __CMK_realtime Efficient Object-Oriented and Template Microcontroller Programming, DOI 10.1007/978-3-642-34688-0,  2013

#[@http://lists.boost.org/Archives/boost/2012/04/192165.php Boost archive]

# [@http://www.exploringbinary.com/ Exploring Binary]  Blog by Rick Regan, 2015.

# [@http://www.drdobbs.com/cpp/optimizing-math-intensive-applications-w/207000448
Optimizing Math-Intensive Applications with Fixed-Point Arithmetic], Anthony Williams,  Dr Dobbs March 2008.

# [@https://en.wikipedia.org/wiki/Fixed-point_arithmetic Fixed-point arithmetic]

# [@https://en.wikipedia.org/wiki/Libfixmath libfixmath fixed-point library] by Ben Brewer.

# [@https://en.wikipedia.org/wiki/Q_(number_format) Q number format] used to specify fixed-point numbers with (optional) sign,
scaling and fractional parts.

#[@https://software.intel.com/en-us/articles/performance-benefits-of-half-precision-floats Performance Benefits of Half Precision Floats]
Patrick Konsor, Intel 2012. Discusses how using only a 16-bit floating-point type as a ['storage] type
can save much memory when there are very many values to store.
Using less memory can also reduce cache misses and can reduce disk I/O.

The type is always converted to
a __fundamental floating-point type for any computation;
instructions vcvtph2ps and vcvtps2ph are provided to convert to and from 32-bit float efficiently.

* [@https://en.wikipedia.org/wiki/ARM_architecture ARM architecture]

[/todo Need more background references?]

[endsect] [/section:ack References]

[section:conventions Document Conventions]

This documentation aims to use of the following naming and formatting conventions:

* C++ code is in `fixed width font` and is syntax-highlighted in color, for example `double` in blue.
* Other code is in block [^teletype fixed-width font].
* Replaceable text that [*you will need to supply] is in [~italics].
* If a name refers to a free function, it is specified like this:
  `free_function()`; that is, it is in [~code font] and its name is followed by `()`
  to indicate that it is a free function.
* If a name refers to a class template, it is specified like this:
  `class_template<>`; that is, it is in code font and its name is followed by `<>`
  to indicate that it is a class template.
* If a name refers to a function-like macro, it is specified like this: `MACRO()`;
  that is, it is uppercase in code font and its name is followed by `()` to
  indicate that it is a function-like macro. Object-like macros appear without the
  trailing `()`.
* Names that refer to ['concepts] in the generic programming sense
(like template parameter names) are specified in CamelCase, for example [^IntegralRange].

[endsect] [/section:conventions Document Conventions]

[xinclude autodoc.xml] [/ Using Doxygen reference documentation.]

[/Only want this if index enabled on the command line like fixed_point\doc>b2 --enable-index --hash]
[section:indexes Indexes]

[/Complete index]
[/'''<index/>''' can now be written as ]
[index]

[/Separate type indexes]
[//modular-boost/tools/auto_index/doc/html/index.html Boost autoindex ]
[/named_index type title] [/see modular-boost/tools/auto_index/doc/html/boost_autoindex/qbk.html]
[named_index function_name Function Index]
[named_index class_name Class Index]
[named_index typedef_name Typedef Index]
[named_index macro_name Macro Index]  [/NO entries in this yet????]
[endsect] [/section:indexes Indexes]





