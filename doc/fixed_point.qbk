[/
  Copyright 2013 Christopher Kormanyos.
  Copyright 2015 Paul A. Bristow.
  Copyright 2015 Nikhar Agrawal.

  Distributed under the Boost Software License, Version 1.0.
  (See accompanying file LICENSE_1_0.txt
  or copy at http://www.boost.org/LICENSE_1_0.txt).
]

[article Boost.Fixed-point
    [quickbook 1.7]
    [copyright 2013, 2015 Christopher Kormanyos]
    [license
         Distributed under the Boost Software License, Version 1.0.
         (See accompanying file LICENSE_1_0.txt or copy at
         [@http://www.boost.org/LICENSE_1_0.txt])
    ]
    [id fixed]
    [authors [Kormanyos, Christopher], [Agrawal, Nikhar], [Bristow, Paul A.]]
    [/last-revision $Date: 2011-07-08 18:51:46 +0100 (Fri, 08 Jul 2011) $]
] [/article Boost.Fixed-point]

[warning This is NOT yet a Boost library and is subject to change and development.]

[caution This documentation is incomplete and subject to change.]

[import ../../../tools/auto_index/include/auto_index_helpers.qbk]
[/ auto_index_helpers.qbk MUST be FIRST included file!]
[/If index enabled on the command line fixed_point\doc>b2 --enable-index --hash]
[/If enable index, then  --hash option is essential because names become to long.]
[/The message is entirely inscrutable!]

[import html4_symbols.qbk]

[/import ../example/fixed_point_snips.cpp -see example and other sections]

[template super[x]'''<superscript>'''[x]'''</superscript>''']
[template sub[x]'''<subscript>'''[x]'''</subscript>''']

[template equation[name]  '''<inlinemediaobject>
<imageobject role="html">
<imagedata fileref="../'''[name]'''.png"></imagedata>
</imageobject>
<imageobject role="print">
<imagedata fileref="../'''[name]'''.svg"></imagedata>
</imageobject>
</inlinemediaobject>''']

[/ External links]
[def __cpp_standard [@http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4382.pdf C++ draft standard]]
[/Note that is just a recent draft, not an actual standard]

[def __boost_license [@http://www.boost.org/LICENSE_1_0.txt Boost License]]
[def __boostbook [@http://www.boost.org/doc/html/boostbook.html BoostBook]]
[def __boostbook_docs [@http://www.boost.org/doc/libs/release/doc/html/boostbook.html BoostBook documentation]]
[def __quickbook  [@http://www.boost.org/doc/tools/quickbook/index.html Quickbook]]
[def __quickbook_syntax [@http://www.boost.org/doc/libs/release/doc/html/quickbook/ref.html Quickbook Syntax Compendium]]
[def __docbook [@http://www.docbook.org/ DocBook]]
[def __doxygen [@http://www.doxygen.org/ Doxygen]]
[def __doxygen_conditionals [@http://www.stack.nl/~dimitri/doxygen/manual/commands.html#cmdcond Doxygen conditional command \cond ... \endcond]]
[def __pdf [@http://www.adobe.com/products/acrobat/adobepdf.html PDF]]
[def __inkscape [@http://www.inkscape.org Inkscape]]
[def __autoindex  [@http://www.boost.org/doc/libs/release/tools/auto_index/doc/html/index.html Automatic Indexing]]

[def __boost [@http://www.boost.org/ Boost]]
[def __boost_archives [@http://lists.boost.org/Archives/boost/ Boost archives]]
[def __boostroot [@boost: Boost root ./modular-boost]]
[def __boost_license [@http://www.boost.org/LICENSE_1_0.txt Boost License]]
[def __multiprecision [@boost:/libs/multiprecision/doc/html/index.html Boost.Multiprecision]]
[def __serialization [@http://www.boost.org/doc/libs/1_58_0/libs/serialization/doc/index.html Boost.Serialization]]
[def __cpp_int [@http://www.boost.org/doc/libs/release/libs/multiprecision/doc/html/boost_multiprecision/tut/ints/cpp_int.html cpp_int]]
[def __cpp_dec_float [@boost:/libs/multiprecision/doc/html/boost_multiprecision/tut/floats/cpp_dec_float.html cpp_dec_float]]
[def __cpp_bin_float [@boost:/libs/multiprecision/doc/html/boost_multiprecision/tut/floats/cpp_bin_float.html cpp_bin_float]]
[def __boost_test [@boost:/libs/test/doc/html/index.html Boost.Test]]
[def __boost_timer [@boost:/libs/timer/doc/index.html Boost.Timer]]
[def __boost_test_fp [@boost:/libs/test/doc/html/boost_test/users_guide/testing_tools/testing_floating_points.html Boost.Test floating-point comparison]]
[def __boost_math_fp [link math_toolkit.float_comparison Boost.Math floating-point utilities]]
[def __boost_math_constants [@http://www.boost.org/doc/libs/release/libs/math/doc/html/math_toolkit/constants.html Boost.Math constants]]
[def __multiprecision_limits_table [@http://www.boost.org/doc/libs/release/libs/multiprecision/doc/html/boost_multiprecision/tut/limits/limits32.html Numeric limits for a 32-bit platform]]
[def __float_distance [@boost:/libs/math/doc/html/math_toolkit/next_float/float_distance.html Boost.Math float_distance]]
[def __ulp [@http://en.wikipedia.org/wiki/Unit_in_the_last_place  Unit in the last place (ULP)]]
[def __SSE2 [@http://en.wikipedia.org/wiki/SSE2 SSE2 instructions]]
[def __WolframAlpha [@http://www.wolframalpha.com/ Wolfram Alpha]]
[def __ARM_architecture  [@https://en.wikipedia.org/wiki/ARM_architecture ARM architecture]]
[def __harvard_architecture [@https://en.wikipedia.org/wiki/Harvard_architecture Harvard architecture]]
[def __von_neumann [@https://en.wikipedia.org/wiki/Von_Neumann_architecture Von Neumann architecture]]
[def __microcontroller [@https://en.wikipedia.org/wiki/Microcontroller microcontroller]]
[def __Arduino [@https://www.arduino.cc/ Arduino]]
[def __Q_format [@https://en.wikipedia.org/wiki/Q_(number_format) Q number format]]
[def __floating_point  [@http://en.wikipedia.org/wiki/Floating_point Floating point]]
[def __epsilon [@http://en.wikipedia.org/wiki/Machine_epsilon machine epsilon]]
[def __ADL [@http://en.cppreference.com/w/cpp/language/adl Argument Dependent Lookup (ADL)]]
[def __function_template_instantiation [@http://en.cppreference.com/w/cpp/language/function_template Function template instantiation]]
[def __fundamental_types [@http://en.cppreference.com/w/cpp/language/types fundamental types]]
[def __guard_digits [@http://en.wikipedia.org/wiki/Guard_digit guard digits]]
[def __representable [@http://en.wikipedia.org/wiki/Floating_point#Representable_numbers.2C_conversion_and_rounding representable]]
[def __IEEE754 [@https://en.wikipedia.org/wiki/IEEE_floating_point IEEE floating-point]]
[def __float_format [@https://en.wikipedia.org/wiki/Single-precision_floating-point_format 32-bit float format]]
[def __double_format [@https://en.wikipedia.org/wiki/Double-precision_floating-point_format 64-bit double format]]
[def __quad_format [@https://en.wikipedia.org/wiki/Quadruple-precision_floating-point_format 128-bit quad format]]
[def __n3352 [@http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2012/n3352.html C++ Binary Fixed-Point Arithmetic N3352]]
[def __CMK_realtime [@http://dx.doi.org/DOI:10.1007/978-3-642-34688-0 Real-Time C++, C M Kormanyos]]
[/See https://en.wikipedia.org/wiki/Digital_object_identifier Note B on specifying links to DOI.  http://dx.doi.org/DOI seems to work best.]
[def __NaN [@https://en.wikipedia.org/wiki/NaN NaN]]
[def __cmath [@http://www.cplusplus.com/reference/cmath/ cmath]]
[def __nan [@http://www.cplusplus.com/reference/cmath/nan-function/ C++ nan function]]
[def __infinity [@http://www.cplusplus.com/reference/cmath/INFINITY/?kw=INFINITY  infinity]]
[def __isnan [@http://www.cplusplus.com/reference/cmath/isnan/?kw=isnan  isnan function]]
[def __isinf [@http://www.cplusplus.com/reference/cmath/isinf/  isinf function]]
[def __numeric_limits [@http://www.cplusplus.com/reference/limits/numeric_limits/ numeric_limits]]
[def __edge [@https://en.wikipedia.org/wiki/Edge_case edge case]]
[def __corner [@https://en.wikipedia.org/wiki/Corner_case corner case]]
[def __boundary [@https://en.wikipedia.org/wiki/Boundary_case boundary case]]
[def __significand [@https://en.wikipedia.org/wiki/Significand significand]]
[def __cmath [@http://en.cppreference.com/w/cpp/numeric/math C math]]
[def __frexp [@http://en.cppreference.com/w/cpp/numeric/math/frexp frexp]]
[def __ldexp [@http://en.cppreference.com/w/cpp/numeric/math/ldexp ldexp]]

[def __is_fundamental [@http://en.cppreference.com/w/cpp/types/is_fundamental std::is_fundamental]]
[def __is_arithmetic [@http://en.cppreference.com/w/cpp/types/is_arithmetic std::is_arithmetic]]
[def __is_floating_point[@http://en.cppreference.com/w/cpp/types/is_floating_point std::is_floating_point]]
[def __is_iec559 [@http://en.cppreference.com/w/cpp/types/numeric_limits/is_iec559 std::numeric_limits::is_iec559]]
[def __cardinal [@https://en.wikipedia.org/wiki/Cardinal_number cardinal]]
[def __radix [@https://en.wikipedia.org/wiki/Radix  radix]]

[/Links to classes etc]

[def __negatable [classref boost::fixed_point::negatable  negatable]]
[def __negatable_value_type [classref boost::fixed_point::negatable::value_type  value_type]]
[def __negatable_float_type [classref boost::fixed_point::negatable::float_type  float_type]]
[def __nonnegative [classref boost::fixed_point::nonnegative  nonnegative]]

[/Unclear how to get a link to the tempate parameters??? So link to class negatable for now.]
[def __range [classref boost::fixed_point::negatable  IntegralRange]]
[def __resolution [classref boost::fixed_point::negatable  FractionalResolution]]
[def __round [memberref boost::fixed_point::negatable  RoundMode]]
[def __overflow [memberref boost::fixed_point::negatable  OverflowMode]]

[/def __range [classref boost::fixed_point::negatable::integral_range  integral_range]]
[/def __resolution [memberref boost::fixed_point::negatable::fractional_resolution  fractional_resolution]]
[/def __round [memberref boost::fixed_point::negatable  round_mode]]
[/def __overflow [memberref boost::fixed_point::negatable  OverflowMode]]

[/ Round modes]
[def __round_fastest [classref boost::fixed_point::round::fastest  round::fastest]]
[def __round_negative [classref boost::fixed_point::round::negative  round::negative]]
[def __round_truncated [classref boost::fixed_point::round::truncated round::truncated]]
[def __round_positive [classref boost::fixed_point::round::positive  round::positive]]
[def __round_classic [classref boost::fixed_point::round::classic  round::classic]]
[def __round_nearest_even [classref boost::fixed_point::round::nearest_even  round::nearest_even]]
[def __round_nearest_odd [classref boost::fixed_point::round::nearest_odd  round::nearest_odd]]

[/ overflow template parameter options]
[def __overflow_undefined [classref boost::fixed_point::overflow::undefined overflow::undefined]]
[def __overflow_impossible [classref boost::fixed_point::overflow::impossible overflow::impossible]]
[def __overflow_modulus [classref boost::fixed_point::overflow::modulus overflow::modulus]]
[def __overflow_saturate [classref boost::fixed_point::overflow::saturate overflow::saturate]]
[def __overflow_exception [classref boost::fixed_point::overflow::exception overflow::exception]]

[/Other links to functions]
[def __pi [memberref boost::fixed_point::negatable::constant_maker::pi pi()]]
[def __ln_two [memberref boost::fixed_point::negatable::constant_maker::ln_two]]

[/Links to sections within fixed_point]
[def __examples [link fixed.examples examples]]
[def __intro [link fixed.intro introduction]]

[section:intro Introduction]
The Boost.Fixed-point Library provides fixed-point types in C++ that have different
range and precision than C++'s ordinary built-in types.
The Fixed-point types can also interoperate with the
built-in types in C++ using clearly defined conversion rules.
This allows Boost.Fixed-point to be used for all
kinds of mathematical calculations involving integer,
rational and floating-point types requiring extended range and precision.

The Fixed_point library is based on proposal __n3352 from Lawrance Crowl.
The internal representation of a binary fixed-point type is an integral
value that has a fixed number of integral range digits before the binary point,
and another fixed number of fractional resolution digits after the point.

The integral value can use a __fundamental integral type from `signed char` to `long long`,
additional types like `__int64` or `__int128`, and, if these are too small, then
a multiprecision integer from __multiprecision.

Proposal __n3352 specifies four different types of fixed-point representations:
`cardinal`, `integral`, `nonnegative` and `negatable`.[br]
The proposed cardinal and integral types represent unsigned and signed integers,
respectively, with zero fractional resolution bits. [br]
The proposed nonnegative and negatable types represent
unsigned and signed fixed-point numbers, respectively, having both zero or more
integral range bits and one or more fractional resolution bits.[br]
The signed fixed-point types require one bit for the sign.

The integer part is located as more significant than the fractional part.
This means that if there is a carry from an addition to the fractional part,
it simply carrys into the integer part, which means that fast integer instructions can be used.
(There is no normalization that is required by floating-point).

So fixed-point trades range and precision for (potentially) improved efficiency
using integer-based computation.

The __Q_format is often used to specify the number of bits used for range and resolution.

Consider, for example, a Q15.16 representation of negatable. It has one sign bit,
15 integral range bits and 16 fractional resolution bits.
This format fits neatly into a 32-bit two's complement signed integer.
[/Giving a total spread of values from 1.526e-005 to 3.277e+004  in steps of 1.526e-005.]
Giving a total spread of signed values from about 0.000015 to 32770  in steps of 0.000015.[br]
Use `boost::fixed_point::negatable<15, -16>` for this fixed-point type.

A small Q7.8 representation has a sign bit, 7 bits of integer part before the binary point,
and 8 bits for the fractional part that can fit into a 16-bit `short`.

The Q7.8 represent can hold integer part values from 0 to 2[super 7] = 127,
and fraction part from 0 to 1/2[super 8] = 1/256 = 0.00390625.
[/Giving a total spread of values from  0.00396 to 127.996 in steps of 0.00396.]
Giving a total spread of values from  about 0.004 to 128 in steps of 0.004.[br]
Use `boost::fixed_point::negatable<7, -8>` for this fixed-point type.

A tiny byte-sized Q2.5 representation has a sign bit, 2 bits of integer part before the binary point,
and 5 bits for the fractional part that can fit into a 8-bit `signed char`.

The Q2.5 representation can hold integer part values from 0 to 2[super 2] = 4,
and fraction part from 0 to 1/2[super 5] = 1/32 = 0.003125.
[/Giving a total spread of values from  0.003125 to 3.696 in steps of 0.003125.]
Giving a total spread of values from  about 0.003 to 4 in steps of 0.003.[br]
Use `boost::fixed_point::negatable<2, -5>` for this fixed-point type.

At the moment, there are several differences between the Fixed_point Library
and proposal __n3352. This fixed-point library only implements a subset of
proposal __n3352 including the `nonnegative` and `negatable` representations only.
In addition, proposal __n3352 specifies seven rounding modes and five
overflow modes. This library, however, supports only two common
rounding modes and two common overflow modes. Proposal __n3352 does not
mention any interaction of with elementary transcendental functions.
The Boost.Fixed-point Library, however, has nearly complete support of `cmath` functions
for the negatable representation and partial support of `cmath` functions
for the nonnegative representation.

[section:why_fixed_point Why Fixed-Point?]

For most computing tasks, floating-point works very well.

* The __IEEE754 layout is very cleverly devised to provide a good resolution and a wide exponent range
making very efficient use of the 32 and 64 bits available
(including an cunning extra implicit significand bit).
* Hardware microcode, refined for decades, provides very fast instructions.

There are, nonetheless, a variety of application domains for which fixed-point
calculations can be preferable to floating-point calculations.

* Certain numerical calculations such as graphics, mathematical
fractals and geometric representations may preferably use
fixed-point rather than floating-point.

* Fixed-point calculations can also be useful in
cost-sensitive real-time embedded systems.
Many microcontrollers, do not have instructions or emulation
for floating-point calculations. Typical examples
are 8 and 16-bit __microcontroller, especially those suited
for high-volume, price-optimized applications.
In these kinds of applications, fixed-point calculations can be
more efficient than software-emulated floating-point calculations
and therefore more well-suited for small 8 or 16-bit microcontrollers.

* High-performance microcontrollers often have an FPU.
Deactivating the FPU and preferentially using fixed-point
instead of floating-point can, nonetheless, be beneficial
for certain reasons. Some project guidelines forbid the use of
floating-point calculations because these potentially
lead to higher consumption of resources such as stack,
FPU registers, memory, overhead of context-switch, etc.
In addition, even high-performance microcontrollers that have FPUs may
have circuitry that can enable or disable the FPU,
and powering the FPU can cost energy.
In these cases, deactivating the FPU and using fixed-point
instead of floating-point can potentially save energy in
low power-consumption modes.

* In fact, then, the main reason to choose fixed-point may be [*to reduce power consumption];
that often means longer battery life, helpful for portable devices like watches, but
even more for implanted medical devices and space-craft where battery charges and changes
are especially inconvenient.

* Storing many floating-point values takes up more memory than would be possible using `fixed_point`.
Memory is cheap, but using less can speed data transfer and reduce cache misses.
So if an entire array of data can be stored as a `negatable`
using a small integral type ,`byte` or `short int`, in a very fast memory cache,
it might be processed more quickly.

* If a resolution greater than `double` is required, `fixed_point` may prove faster.[br]
Software like __multiprecision can provide much higher resolution and higher exponent ranges,
but at a great cost in computation time, often a hundred-fold slower.[br]
Fixed-point using many bits, for example 256-bit, can provide very high resolution,
while may execute faster than an equivalent __multiprecision type (provided
the reduced exponent (scaling) range can be tolerated).

* Rationalized integer calculations (and even fixed-point)
can be more reliable than floating-point emulations
and potentially improve robustness by remaining
in the realm of near-integral math.

[endsect] [/section:why_fixed_point Why Fixed-Point?]

[section:why_this_fixed_point  Why use Boost.Fixed-point?]

A number of fixed_point libraries have been written; why would one choose this library?

* Boost free for all uses, including commercial.

* Compatible with C++ standard including `std::numeric_limits` and `cmath` libraries.

* Range and resolution are chosen using C++ templates.

* The smallest underlying power-of-2 hardware type (byte, word, dword ...)
will be chosen automatically.

* Rounding and overflow may be controlled using C++ templates.

* Extends to use underlying __fundamental_types automatically.

* Extends to use __multiprecision when the resolution and/or range specified are too big to
fit into the largest of the __fundamental_types.
This allows fixed-point type with much higher resolution and/or range
than any other library. This is a unique feature.

* Convenient header-only implementation (even when extended to __multiprecision).

* Visible tests.

[endsect] [/section:why_this_fixed_point  Why use Boost.Fixed-point]

[endsect] [/section:intro Introduction]

[section:examples Examples]

[section:numeric_limits Example of a fixed_point type and its numeric_limits]

[import ../example/fixed_point_demo_basic.cpp]

In order to use the fixed_point library, we first need an include:

[fixed_point_include_1]

Then it is convenient (because we are likely to reuse the type name often)
to define a `typedef` for our chosen fixed-point type

[fixed_point_typedef_1]

This example uses the fixed-point class __negatable
(the analog of a signed floating-point) defined to have
a template parameter __resolution of 15
and a template parameter __range of -16.

This means that 15 bits are used for the __significand or fraction part and
16 for the binary exponent or range factor.

(For simplicity, we use the defaults for the other template parameters,
`round_mode` = __round_fastest and `overflow_mode` = __overflow_undefined).

[tip Choosing a total of range and resolution (and allowing an extra bit for sign)
so that the total is a power of 2 is very sensible. [br]
Choosing just one extra bit would mean
that the underlying __fundamental_types will be twice as wide![br]
]
[warning Choosing a combination that does not quite fit into the largest available integral type
(usually 32 or 64 bits) can have a dramatic effect because a __multiprecision type will be used.]

We can show the __numeric_limits for this type thus:

[show_numeric_limits_1]

and the output is:

[numeric_limits_output_1]

Next we can use this defined fixed-point type, constructing from two integer values to avoid
any conversion from a floating-point value whose value is probably not exactly __representable.
This ensures no loss of precision or double rounding during construction.

[fixed_example_1]

We can inspect the __significand or fraction (also called  mantissa but this term is now deprecated)
and the exponent parts using the using __cmath function __frexp, and alter the exponent using __ldexp.

Of course, other __cmath functions such as trigonometric, exponential, logarithmic, etc.
(`#include <cmath>`) are available. These have been injected into the global namespace
via `using` directive. Thus the user can simply call, for example,
`sqrt(negatable)` without requiring any namespace decoration.

TODO Examples snippet needed here.

(See rationale for more details on this).

[warning Some __cmath functions are not applicable to `fixed_point` values;
others may not yet be implemented.]

The full code is at  [@../../example/fixed_point_constants.cpp  fixed_point_constants.cpp].


[endsect] [/section:numeric_limits Example of a fixed_point type and its numeric_limits]

[section:bare_derivative Example of a bare-metal fixed_point type evaluating  derivative.]

[import ../example/fixed_point_bare_metal_derivative_example.cpp]

This example shows how a fixed_point type can be used in an 8-bit micrcontroller
to evaluate the first derivative (and that can be used, for example, to trigger some action).

It evaluates the first derivative of a real function
using a three-point central-difference rule of ['O(dx^6)].

For more details see this section on
[@http://www.boost.org/doc/libs/release/libs/multiprecision/doc/html/boost_multiprecision/tut/floats/fp_eg/nd.html Calculating a derivative].

The derivative code is

[fixed_point_derivative_function]

The fixed_point 16-bit `negative` type and the coefficients are

[fixed_point_derivative_coeffic]

Evaluation is at 1/2 and uses a step size of 1/4.

(see [@http://link.springer.com/chapter/10.1007/978-3-642-34688-0_12 page 219-220]).

[fixed_point_derivative_evalution]

The expected exact differential is ((2 * a) + b) = (2.4 + 3.4) = 4.6.
We obtain a fixed-point result of approximately 4.5938.

To verify that the result lies within ['4.5 < result < 4.7]
(since the expected result is 4.6, this is a wide tolerance):

[fixed_point_verify]

In a bigger system, we could display the result by sending to an output stream,
but our hardware may have no way of doing this
(perhaps only toggling a digital output to take some action like switch an LED on).

So this example shows how to avoid the big overhead of `std::ostream` code
by defining two macros either on the command line, or by adding

  #define BOOST_FIXED_POINT_DISABLE_MULTIPRECISION // Do not use Boost.Multiprecision.
  #define BOOST_FIXED_POINT_DISABLE_IOSTREAM       // Do not use I/O streaming.

before this include

  #include <boost/fixed_point/fixed_point.hpp>

Full code is at [@../../example/fixed_point_bare_metal_derivative_example.cpp  fixed_point_bare_metal_derivative_example.cpp].

This example is also discussed in C.M. Kormanyos, Real-Time C++: Efficient Object-Oriented and
Template Microcontroller Programming (Springer, Heidelberg, 2013).
in Section 12.7 and [@http://link.springer.com/chapter/10.1007/978-3-642-34688-0_13 Chapter 13].

[endsect] [/section:bare_derivative Example of a bare-metal fixed_point type evaluating  derivative.]

[endsect] [/section:examples Examples]

[section:conversions Constructing and Interconverting Between Number Types]
All of the fixed-point types in the Fixed_point Library have certain conversion rules in common.
In particular:
[endsect] [/section:conversions Constructing and Interconverting Between Number Types]

[section:mixed Mixed Precision Arithmetic]
Mixed precision arithmetic is fully supported by the library.

There are several different forms:

* Where the operands are of different range and equal resolution.
* Where the operands are of equal range and different resolution.
* Where the operands are of different range and different precision.

Some design choices were made.

For example, the result of `(a + b)` has the type of
the operand with the wider resolution.
Some might argue that the result of `(a + b)` should
have the type of ['a] or the type of ['b], etc.
Mixed-math fixed-point binary arithmetic could be
implement either way; it's just a design choice.

For mixed-math comparison, a so-called supra-negatable type
is created from the maximum of both range and resolution
of both operands. A comparison is then made.

This results in such comparisons like

  negatable<4, -8>(1) / 3 != negatable<3, -11>(1) / 3

And the result is symmetric, otherwise, we might be surprised that
  `(a == b)`
and
  `(b != a)`

This is yet another design choice.

[endsect] [/section:mixed Mixed Precision Arithmetic]

[section:constants Constants]
[import ../example/fixed_point_constants.cpp]

Constants (as far as they are yet implemented) can be easily used.

The underlying values are from __boost_math_constants and are used to construct fixed_point types
with a suitable precision for the number of bits in the significand.

To start, we can generate a 'reference' value using __multiprecision, say with 50 decimal digits precision.

[bin_float_50_pi]

Note how we ensure that only significand digits ['for the type] are shown by using

  std::setprecision(std::numeric_limits<cpp_bin_float_50>::digits10)

Then we can generate using a typical fixed-point type that will
use a 64-bit integer as its underlying representation.

[fixed_point__constant]

Then a tiny (and so rather imprecise) fixed-point type
that will fit into a single byte.

The result would almost meet the requirements of the
[@https://en.wikipedia.org/wiki/Indiana_Pi_Bill Indiana pi bill]!

Finally a much more precise fixed_point type that will fit into 128-bit (16-byte).

[fixed_point_precise_constant]

The full code is at [@../../example/fixed_point_constants.cpp  fixed_point_constants.cpp].

[endsect] [/section:constants Constants]

[section:how_to_tell How to Determine the Kind of a Number From `std::numeric_limits`]

Based on the information above, one can see that different kinds of numbers can be
differentiated based on the information stored in `std::numeric_limits`.  This is
in addition to the `traits class`
[@http://www.boost.org/doc/libs/release/libs/multiprecision/doc/html/boost_multiprecision/ref/number.html#boost_multiprecision.ref.number.traits_class_support traits class support]
provided by this library.

[endsect] [/section:how_to_tell How to Determine the Kind of a Number From `std::numeric_limits`]

[section:fixed_versus_float Comparison of Fixed-point and Floating-point Formats]

We can compare the ubiquitous __IEEE754 types

* __float_format  1 sign bit, 8 exponent bits, 23 stored bits  (+1 implicit not-stored bit)

* __double_format 1 sign bit, 11 exponent bits, and 52 stored bits (+1 implicit not-stored bit)

and the extended precision type (usually implemented in software, and thus much slower)

* __quad_format 1 sign bit, 15 exponent bits, 112 stored bits (+1 implicit not-stored bit)

Using fixed point `negatable`, we can chose make quite different splits between exponent (range)
and significand (resolution).

For example, to match the range of `float` using only 32-bit, we can define

  typedef boost::fixed_point::negatable<11, -20> fixed_point_type;

We could also match the resolution of `float` using only 32-bit,
by defining

  typedef boost::fixed_point::negatable<7, -24> fixed_point_type;

Or we can use all 31 bits for resolution (note that we still need
one sign bit for signed type `negatable`)

  typedef boost::fixed_point::negatable<0, -31> fixed_point_type;

or we can use nearly all bits for range with

  typedef boost::fixed_point::negatable<29, -2> fixed_point_type;

Note that not all the `std::numeric_limits` member constants and functions
are meaningful for all user-defined types (UDT),
such as the decimal and binary multiprecision types provided here.
More information on this is given in the sections below.
[#numeric_limits_tables] [/ Anchor for Tables of values for numeric_limits for various built-in and cpp_bin_float types]

[include fixed_point_types_table.qbk] [/Complete section containing generated table]
[include floating_point_types_table.qbk] [/Complete section containing generated table]

See [link fixed.fixed_versus_float.fixed_point_limits fixed_point numeric_limits_tables],
and [link fixed.fixed_versus_float.floating_point_limits floating_point numeric_limits_tables.]

(A wider range of floating-point types, including __multiprecision, is at __multiprecision_limits_table).

[h3:type_example Examples of boost::fixed_point::negatable<11, -20>]

This type has a similar distribution of bits usage to `float`
except that IEEE floating point types have an implicit bit that is not stored.

Epsilon is 9.54e-7 compared to `float` 1.2e-7
The range is 2000 compared to `float` 3.4e38.


If we use nearly all the bits for range, (`negatable<29,-2>`) then `epsilon` is 0.25,
but `max` is 5.4e8.

If we try to use all bits for range, then this is not supported and a `static assert`
issues a compiler error thus

  Error: The fractional resolution of negatable must be negative and include at least 1 fractional bit.

This would be the same as using a 32-bit `int` whose `max` is = 2147483647 or 2.14e9,
and conceptually `epsilon` would be unity.
(For integral types `std::numeric_limits<>::epsilon()` is not meaningful and is left as zero).
Using all possible bits for range `negatable<30,-1>` has a `max` of half of `int` and an `epsilon` of 0.5.
These two extreme examples probably do not have much practical use.

If we use all 31 bits for resolution, then `max` is merely unity, so we can only store fractions <= 1,
but `epsilon` is reduced to 9.3e-10, much less than `float`, so this might be useful.
[endsect] [/section:fixed_versus_float Comparison of Fixed-point and Floating-point Formats]

[section:representation_types How to tell the Representation types used for a fixed_point type]

Users can (and will) want to know the underlying representations used for a __negatable type.
These are __negatable_value_type and __negatable_float_type.

[import ../example/fixed_point_representation_examples.cpp]

To find the name of the underlying representation used by a particular __negatable type,
one can use the [@ http://www.cplusplus.com/reference/typeinfo/type_info/ type_info class]
with this include:

  #include <typeinfo>

To output the name of fixed_point type `negatable<0, -8>` use the __negatable_value_type:

[fixed_point_type_representation_example_1]

So `signed char` is signed integer type used for representation of this 8-bit fixed-point negatable number.

For low digit counts, this will be a __fundamental_types type such as `int8_t, int16_t, int32_t, int64_t`, etc.
For larger digit counts, this will be a __multiprecision signed integer type.

One might also want to know the floating-point type that is guaranteed to be wide
enough to represent the fixed-point negatable number in its entirety.

For this use __negatable_float_type:

[fixed_point_type_representation_example_2]

showing that `float` is (plenty) big enough to hold all possible values for this tiny type.

To list some other of the many reasonable fixed_point types, an example function is:

[fixed_point_type_representation_example_3]

[tip The full type given by `typeid(T).name()` will be fully informative but may be inconveniently long
because it could be a so-called mangled name.]

The full example and some sample output is at [@../../example/fixed_point_representation_examples.cpp  fixed_point_representation_examples.cpp].

Most of the results are obvious, but it is worth noting that a type that uses a value type of `__int64`
cannot use a 64-bit `double` type for its floating-point representation and must switch to a __multiprecision type, like
`class boost::multiprecision::number<class boost::multiprecision::backends::cpp_bin_float<63,2,void,int,0,0>,0>`
This will have a marked effect on any operation like output that uses this.

[tip Take care choosing fixed_point type.]

[endsect] [/section:representation_types How to tell the Representation types used for a fixed_point type]

[section:headers Header File Structure]

[table Top level headers
[[Header][Contains]]
[[boost/fixed_point/fixed_point.hpp] [includes all other headers]]
[[boost/fixed_point/fixed_point_negatable.hpp] [negatable type]]
[[boost/fixed_point/fixed_point_nonnegative.hpp] [nonnegative type]]
[[boost/fixed_point/fixed_point_round.hpp] [rounding `structs`]]
[[boost/fixed_point/fixed_point_overflow.hpp] [overflow `structs`]]
] [/table Top level headers]

[table Implementation Headers
[[Header][Contains]]
[[boost/fixed_point/detail/fixed_point.hpp] [negatable and nonnegative implemention details]]
[[boost/fixed_point/detail/fixed_point_constants.hpp] [negatable and nonnegative implemention details]]
[[boost/fixed_point/detail/fixed_point_cstdfloat.hpp] [provide local floating-point type definitions having specified widths]]
[[boost/fixed_point/detail/fixed_point_stdfloat.hpp] [provide local floating-point type definitions having specified widths]]
]  [/table Implementation Headers]

[endsect] [/section:headers Header File Structure]

[section:design Design, Implementation and Rationale]

[section:history Historial discussions]

In response to Lawrance Crowl proposal __n3352, this a thread on the __boost discussion list.
See this thread on
[@http://lists.boost.org/Archives/boost/2012/04/191987.php]
on the __boost_archives.

Vicente Botet Escriba produced a prototype at
[@http://svn.boost.org/svn/boost/sandbox/fixed_point]
asked a number if questions,
and replies from the current author Christopher Kormanyos
(that provided the basis for the implementation here) were:

First up, one might want to consider some top-level requirements.

* How might fixed-point fit with an extended complex class?
- If Boost.Multiprecision or a multiprecision type is ever
specified, how might fixed-point fit with it.
- If a multiprecision integer type ever gets specified, should
the representation of fixed-point be allowed to use it for
mantissa and decimal parts?

* Should integers and reals be represented by separated classes?
I don't see the need for integers in the first place.
I'm wondering if the library will be simpler as the operations are not
the same. If we have only one class, enable_if should be used to make
the difference.

* Should signed and unsigned be represented by separated classes?
Yes, in my opinion.
I guess, perhaps, the separate sign information might be a necessity.
But I'm not sure.
I think that when a single word is enough to represent the fixed-point
2's complement is the bets choice. When more than a word is needed,
having the sing on all the word is a lost of space, and as you say
whether it is represented represented by left-most word/limb or as a
separated data should be an internal decision. In this case using more
space seems IMO to be a minor issue.

* Should the library use a specific representation for signed numbers
(separated sign, 2-complement? Let the user choose?)
Very good question. A separate bool flag for sign slows down the library and increases
storage requirements. The sign of the left-most limb could be the sign. But this
breaks down for all-fractional types. I guess, perhaps, the separate sign information
might be a necessity. But I'm not sure.

* Should the library provide arbitrary range and resolution and allocators?
Unfortunately, the allocator seems necessary for high digit counts.
But perhaps a hybrid container with compile-time width for low limb-count
and allocation for a (specifiable, zero allowed) higher limb count could be used here.
But be sure to make fixed-point fast for low digit counts, possibly
using template specialization when the fixed-point can be represented
by a built-in integer type (in assiciation with "get my int type" compile-time helper templates).
This is what I have done in the past. Low digit counts is the key range for fixed.

* Should the library be open to overflow and rounding or just implement some of the possible policies? and in this case which ones?
Where do you start, where do you stop?
This is like the sign bit. Do you want extra information
for the sub-normals or use some magic values?

* Should fixed_point be convertible to/from integer/float/double?
Yes, absolutely, in my opinion. Implicit or explicit conversion?

* Could the result of an arithmetic operation have more range and resolution than his arguments?
No. But copy construction and copy assign maybe, whereby the LHS
dictates the digit count.

* Is there a need for a specific fixed_point I/O?
* Is there a need for a specific I/O?
Yes.

* is there a need for radix other than 2 (binary)?
Coming from a guy who has written [*a lot] of specialized number classes...
I have always been haunted by radix-10. Never again for me.
Radix-2 and don't look back (my opinion).
I prefer also to concentrate on Radix-2 and leave Radix-10 for another library.

* Should the library implement the basic functions, or should it imperatively implement the C++11 math functions? Could a first version just forward to the c++11 math functions?
It should fit in with Boost.Multiprecision, if there ever is such a thing.
Users like me who need a tiny set of trig functions for, say, an
8-bit controller can roll-their-own via template specialization.
Don't even get started with Cordic, Chebyshev, polynomial expansion,
Don't even get started with cordic, Chebyshev, polynomial expansion,
Pade, Taylor, Newton-Raphson, FFT multiplication, AGM, etc., etc., etc. and the rest.
Just make the numbers! We will be happy for that because it's really a lot.
C++ should have the templated math functions and an extended complex type
elsewhere. You just need to make the number types.

* Should the library support just one of the know ways to name a fixed-point, a U(a,b), nQm, ...? Provide some ways to move from one to another?

* Could expect the same/better performances respect to hand written code?
It's implementation-dependent. But if your 7.8 and 15.16 signed splits are
slower than single-precision float on an 8-bit core, you will get flack for it.

* What should be the size used by a fixed_point instance? _fast? _least?
Should the user be able to decide which approach is better for his needs?
It's implementation defined. For small digit counts, I would try to fit it in
a built-in type. For medium digit counts, a fixed, optionally fixed-hybrid container
of `std::uint_fast32_t`. For very high counts, use an established fast integer
representation with its own fast-multiply (like a potential Boost.Multiprecision).

* Which should be the namespace? boost? boost/fixed_point? boost/binary_fixed_point? boost/bfp?
For me, boost/fixed_point.

Phil Endecott observed on overflow:

"Some people conflate fixed point with features like saturation, which
I would prefer to decouple. Fixed-point arithmetic without saturation
is useful, as is integer arithmetic with saturation. So I'd prefer to
make them orthogonal, but compatible, concepts. "

[h4 nonnegative and the sign bit]
Is it right that we don't get any more resolution for the unsigned version
`nonnegative` even though we are not using a bit for sign?

This is a tough design choice. It's a bit tricky
for the following reason. The `negatable` class performs
all operations internally with `unsigned` representations,
keeping track of the sign of the result independently.
This allows us to utilize the sign bit for one additional
left shift slot, thereby providing one extra digit for
rounding.

The `nonnegative` class can and does use the full
width of its underlying unsigned data representation.
Internal operations, however, still require one
extra bit for rounding. For this reason, the key
nonnegative examples use types such as
`nonnegative<15, -16>`. The type `nonnegative<16, 16>`
will fill the underlying 32-bit data field entirely, but
will require 65 bits for multiply, divide, etc. So as
it turns out using 31 bits provides for better optimization.

This could of course be solved better
if a there was a more clever `mul` and `div` instead of the current lazy way.
This might be improved later.

[warning Ensure that the sum of resolution and range
is not [*equal] to the number of bits in the underlying integral type, usually `int` 32 or 64-bit.
Other fixed_point will use the next largest type, at worse a __multiprecision type,
with dramatic effect on code size and run time.
For example, `negatable<0,63>` and `nonnegative<0,63>`
are the largest types possible based on `__int64_t` without using __multiprecision.
] [/warning]

[endsect] [/section:history Historial discussions]

[section:layout Layout]

There is a (most significant) bit used for sign, zero if positive, one if negative.

There is [*no] implicit bit as found in most floating-point formats.

[endsect] [/section:layout Layout]

[section:limits Numeric Limits]

[@http://www.exploringbinary.com/ Exploring Binary]

[import  ../example/fixed_point_limits.cpp]

[endsect] [/section:limits Numeric Limits]

[section:macros  Preprocessor Options to disable some features]

Some macros are becoming available to disable some features
that may improve the usefulness of fixed_point in certain applications.

* BOOST_FIXED_POINT_DISABLE_MULTIPRECISION,
defined to disable the use of Boost.Multiprecision
for back-ends of the fixed-point classes.
(not yet implemented).

* BOOST_FIXED_POINT_DISABLE_WIDE_INTEGER_MATH,
defined to avoid using the unsigned_large_type. This option
is intended for systems with limited integer widths
such as bare-metal microcontrollers.[br]
When used in combination with BOOST_FIXED_POINT_DISABLE_MULTIPRECISION,
the this option is intended to provide fixed-point representations
with up to 64-bits (if 64-bit integral types are available)
without requiring any of Boost.Multiprecision.
(not yet implemented).

* BOOST_FIXED_POINT_DISABLE_IOSTREAM defined to disable
all I/O streaming and the inclusion of associated standard
library headers.[br]
This is intended to eliminate I/O stream
overhead, in particular for bare-metal microcontroller projects.
(implemented but not tested).

[/TODO needs a compile-fail test for this macro?]

For an example, see	[@../../example/fixed_point_no_io.cpp fixed_point_no_io.cpp].

* BOOST_FIXED_POINT_DISABLE_CPP11 would decide
to support an optional back-port to C++03 and eliminate
the use of all C++11 language elements. This might send the
wrong message about language technology, but could potentially
increase the range of potential target compilers (especially
for embedded systems). (not yet implemented).

[endsect] [/section:macros  Preprocessor Options to disable some features]

[section:rounding Rounding]

Round has emerged as the most contentious and difficult area.

[#combinatorial_explosion]
Our starting point has been __n3352 that specifies seven rounding modes.
All have some uses and some logic for their inclusion.

Five overflow modes are also specified and this leads to combinatorial explosion,
for example potentially requiring 35 specializations of __limits for each fixed_point type.
So far, only the __negatable class has been implemented, but __n3352 also
describes  nonegative unsigned versions
(as well as integer-only arithmetic __cardinal and signed integral),
potentially at least doubling the code required.

Other libraries are tackling the problem of overflow (and underflow) with integral types in so-called
'safe' integers.


For the rounding mode nearest_even, if the 1/2 __ULP bit 1,
then the result of any operation that leads to a result in the range ['\[x, x+ 1/2 ULP\]]
would round to x and in the range ['(x+1/2ULP, x+1)] would round to x+1.

If the 1/2 __ULP bit is 0, however, then any operation that leads to an intermediate value in the range ['\[x, x+1)] would round to x.

[endsect] [/section:rounding Rounding]

[section:overflow Over and Underflow]

[section:mixed_mode Mixed-mode]

Mixed math  are operations using fixed-point types of [*different range and/or precision].

The minimal set of  needs:

* mixed-math ctors.
* mixed math copy ctor.
* mixed-math global operators add, sub, mul, and div.
* mixed-math comparison operators.

Design choices were made that the result of ['(a + b)] has the type of ['a].

This might be controversial,
as some might argue that the result of ['(a + b)] should
have the highest precision. It's easy to implement either
way, just a design choice.

For mixed-math comparison, the supra-negatable type
is created from the [*maximum of both range and resolution].
A comparison is then made.

This results in such things like

  negatable<4, -8>(1) / 3 != negatable<3, -11>(1) / 3

And the result is symmetric. Otherwise, we might
end up with (a == b) and (b != a). It's another
design choice.

[endsect] [/section:mixed_mode Mixed-mode]


[endsect] [/section:overflow Over and Underflow]

[section:infinity Infinity and NotANumber (NaN)]

Unlike floating-point types, the fixed-point types (may)
occupy the entire underlying integer type,
and no bit patterns are reserved for __NaN or __infinity.
The `bool std::numeric_limits<T>::has_infinity`
and `bool std::numeric_limits<T>::has_quiet_NaN` both
return `false` for all fixed-point types.

Lack of an encoding for infinity or NaN means that overflow or underflow must be signalled differently.[br]

A template parameter `typename OverflowMode`  is provided to permit control what happens on overflow or underflow.
In `namespace overflow` some `struct` like `modulus`, `exception` etc are provided.

[endsect] [/section:infinity Infinity and NotANumber (NaN)]

[section:cmath C math functions injected into global namespace]

As briefly mentioned previously, all implemented __cmath functions
are injected into the global namespace with `using` directives such as

  using boost::fixed_point::sqrt;

This is very convenient as it allows the user to simply call `sqrt(negatable)` without
requiring any namespace decoration. In this way, the `<cmath>`
functions of the negatable class work just like those for
built-in types in the C-language header `<math.h>`.

So the user can just write:

  fixed_point_type x(42);
  sqrt(x);

(The same strategy has been used in __multiprecision so that
types like __cpp_bin_float can also use math functions freely).

[endsect] [/section:cmath C math functions injected into global namespace]

[section:boostmath Using the Fixed-point Library with Boost.Math]

The Fixed-point Library can be used with Boost.Math,
in particular when using the the __negatable and __nonnegative classes.
Due to limitations in numeric limits of the fixed-point type, however,
care must be taken when selecting the fixed-point range and resolution
for a given calculation.

[endsect] [/section:boostmath Using the Fixed-point Library with Boost.Math]

[section:testing Testing]

Our testing is necessarily focussed on typical use cases and __boundary __edge and __corner cases.

We have performed round-trip testing.

This involves constructing a fixed_point type from decimal digits strings like '0.001, 0.002 ...'
This fixed-point representation is output to a stringstream and then read back into another
fixed-point variable, and the two checked for equality,

This test can be performed for all possible values of small bit-count fixed-point types,
but this would take unfeasible test times for more than about 32-bit,
so roughly random values covering the entire range of possible binary patterns
are used for test values instead.

[note History Random testing was used to track bugs in Microsoft Visual Studio stream
input from decimal digit strings.
A fault was originally discovered by a user of __serialization when he found (after much debugging)
a single value of  de-serialized data that was 1-bit different from that originally written.
Random value testing then revealed that a small range of values could not be round-tripped in this way,
and a third of the values in this range were 1-bit different.
The __cpp_standard does not (yet) ['require] input from decimal digit strings to the nearest __representable value,
but while other [@http://www.exploringbinary.com/visual-c-plus-plus-strtod-still-broken/#more-565 examples]
were also found in all compilers, most are now achieve correct conversion for all values.
]

[endsect] [/section:testing Testing]

[endsect] [/section:design Design, Implementation and Rationale]

[section:faq Frequently Asked Questions FAQ]

#['When should I consider using a fixed-point type?] [br]
Fixed-point allows you to provide a lower or higher range and/or a lower or higher precision.
#['Will a fixed-point type use less memory?] [br]
If you base the fixed-point type on a small underlying integer type, then it will be more efficient.
#['Will a fixed-point type run faster than floating-point type?]  [br]
If there is no hardware floating-point, then is very likely to run much faster.
If you require a very high range or precision that would require __multiprecision or similar
high or arbitrary precision type, then for the same precision or range, it will probably be quicker,
possibly much quicker.
#['How can I avoid using iostream on a bare-metal microcontroller without any peripherals?] [br]
`#define BOOST_FIXED_POINT_DISABLE_IOSTREAM`.

[endsect] [/section:main_faq Frequently Asked Questions FAQ]

[section:howtouse How To Use This Documentation]

This documentation is prepared using the Boost __quickbook, __boostbook, __doxygen, __autoindex toolchain.

Start your search with the

* Table of Contents, but see also:

* Hyperlinks (shown in two colors depending on whether they have been visited, or not).[br]
Considerable work has been put into providing extensive links, so please use them!

* Indexes that link directly to both words in the text and to reference documentation.
Sometimes there are separate indexes for functions, class, macros, but often just one index.
These are automatically produced, so there is some 'clutter'.
If you know you are looking for a function, then a specific index will avoid most clutter.

* Doxygen-derived C++ Reference section.[br]
[tip The colored class and function names are links will lead you to an individual class, function etc
are the key to finding what an item does,
and its parameter, template parameters, pre and post conditions, and returns.]

[tip Having found a class like `negatable`, use the find key to search for a specific function or value.
For example, using the index to search for `value_type` will lead you to the (long) page of
`class template negatable` so then search for `value_type` and click on the link to get the detail.
This is much quicker than simply scrolling.]

The information given is derived from Doxygen-syntax comments in the include files, mainly
[@../../include/boost/fixed_point/fixed_point.hpp fixed_point.hpp].

* Examples will often be your quickest way to find what you need to know.
Examples often deliberately use many features, often in a contrived fashion.
Snippets of syntax-colored code are used in the text.
You can also use links to display the entire source code of examples in the `example` folder.
You should be able to run these examples without modification
and are often a very good starting point to write your own code.

* Tests will also give examples of use. Like examples, there will be links to tests in the `test` folder.

[heading Admonishments]

[note These blocks typically go into more detail about an explanation given above.]

[tip These blocks contain information that you may find helpful while coding.]

[important These contain information that is imperative to understanding a concept.
Failure to follow suggestions in these blocks will probably result in undesired behavior.
Read all of these you find.]

[warning It is wise that you follow these. Failure to do so will lead to
incorrect, and very likely undesired, results.]

[section:conventions Document Conventions]

This documentation aims to use of the following naming and formatting conventions:

* C++ code is in `fixed width font` and is syntax-highlighted in color, for example `double` in blue.
* Other code is in block [^teletype fixed-width font].
* Replaceable text that [*you will need to supply] is in [~italics].
* If a name refers to a free function, it is specified like this:
  `free_function()`; that is, it is in [~code font] and its name is followed by `()`
  to indicate that it is a free function.
* If a name refers to a class template, it is specified like this:
  `class_template<>`; that is, it is in code font and its name is followed by `<>`
  to indicate that it is a class template.
* If a name refers to a function-like macro, it is specified like this: `MACRO()`;
  that is, it is uppercase in code font and its name is followed by `()` to
  indicate that it is a function-like macro. Object-like macros appear without the
  trailing `()`.
* Names that refer to ['concepts] in the generic programming sense
(like template parameter names) are specified in CamelCase, for example [^IntegralRange].

[endsect] [/section:conventions Document Conventions]


[endsect] [/section:howtouse How To Use This Documentation]

[section:perf Performance Comparison]

TODO

[endsect] [/section:perf Performance Comparison]

[section:map Roadmap]

[h4 1.?]

* First Release.
[h4 Post review changes]

[h4 Pre-review history]

[h4 Pre-Review Comments]

* 2015 Christopher Kormanyos  refines the code with the aid of GSoC student Nikhar Agrawal.

* 2013, Christopher Kormanyos develops the all C++ arithmetic fixed point code.

[endsect] [/section:map Roadmap]

[section:todo TODO]

Implementation of all rounding modes and overflows. TODO

[endsect] [/section:todo TODO]

[section:ack Acknowledgements, Thanks and Credits]

This library would not have happened without:

* John Maddock's binary floating-point representation and number representation
in __multiprecision.

* [@http://www-cs-faculty.stanford.edu/~uno/taocp.html "The Art Of Computer Programming"],
Donald E. Knuth, Volume 2: Seminumerical Algorithms, Third Edition
(Reading, Massachusetts: Addison-Wesley, 1997), xiv+762pp. ISBN 0-201-89684-2

We are grateful for Google for support of Nikhar Agrawal for support through the
[@http://code.google.com/soc/2007/ Google Summer of Code (2015) program].

[@http://lists.boost.org/Archives/boost/2012/04/191987.php Vicente Botet Escriba ] posed a lots of questions about a design.
As a result of reading Lawrence Crowl's proposal __n3352,
Vicente Botet Escriba prototyped a [@http://svn.boost.org/svn/boost/sandbox/fixed_point fixed-point library] in 2013.

[@http://2015.cppnow.org/participant/vicente-j-botet-escriba/ Phil Endecott reviewed past discussions on fixed-point.]


[endsect] [/section:ack Acknowledgements]

[section:references References]

#__n3352

#  Efficient Object-Oriented and Template Microcontroller Programming,
__CMK_realtime, ISBN 978-3-642-34688-0,  2013,

#[@http://lists.boost.org/Archives/boost/2012/04/192165.php]
[/ Boost archive thread:fixed_point:Request for interest in a binary fixed point library]

# [@http://www.exploringbinary.com/ Exploring Binary]  Blog by Rick Regan, 2015.

# [@http://www.drdobbs.com/cpp/optimizing-math-intensive-applications-w/207000448
Optimizing Math-Intensive Applications with Fixed-Point Arithmetic], Anthony Williams,  Dr Dobbs March 2008.

# [@https://en.wikipedia.org/wiki/Fixed-point_arithmetic Fixed-point arithmetic]

# [@https://en.wikipedia.org/wiki/Libfixmath libfixmath fixed-point library] by Ben Brewer.

# [@https://en.wikipedia.org/wiki/Q_(number_format) Q number format] used to specify fixed-point numbers with (optional) sign,
scaling and fractional parts.

#[@https://software.intel.com/en-us/articles/performance-benefits-of-half-precision-floats Performance Benefits of Half Precision Floats]
Patrick Konsor, Intel 2012. Discusses how using only a 16-bit floating-point type as a ['storage] type
can save much memory when there are very many values to store.
Using less memory can also reduce cache misses and can reduce disk I/O.

The type is always converted to
a __fundamental_types floating-point type for any computation;
instructions vcvtph2ps and vcvtps2ph are provided to convert to and from 32-bit float efficiently.

* [@https://en.wikipedia.org/wiki/ARM_architecture ARM architecture]

[/todo Need more background references?]

[endsect] [/section:ack References]

[xinclude autodoc.xml] [/ Using Doxygen reference documentation.]

[/Only want this if index enabled on the command line like fixed_point\doc>b2 --enable-index --hash]
[section:indexes Indexes]

[/Complete index]
[/'''<index/>''' can now be written as ]
[index]

[/Separate type indexes]
[//modular-boost/tools/auto_index/doc/html/index.html Boost autoindex ]
[/named_index type title] [/see modular-boost/tools/auto_index/doc/html/boost_autoindex/qbk.html]
[named_index function_name Function Index]
[named_index class_name Class Index]
[endsect] [/section:indexes Indexes]





